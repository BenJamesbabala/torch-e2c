{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images\n",
    "#### by Manuel Watter, Jost Tobias Springenberg, Joschka Boedecker, Martin Riedmiller\n",
    "##### http://arxiv.org/abs/1506.07365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MIT License (MIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impementation Copyright (c) 2015, John-Alexander M. Assael (iassael@gmail.com) & Marc P. Deisenroth. All rights reserved."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "this software and associated documentation files (the \"Software\"), to deal in\n",
    "the Software without restriction, including without limitation the rights to\n",
    "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n",
    "of the Software, and to permit persons to whom the Software is furnished to do\n",
    "so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if itorch then\n",
    "    arg = {}\n",
    "end\n",
    "\n",
    "cmd = torch.CmdLine()\n",
    "cmd:text()\n",
    "cmd:text('Options')\n",
    "\n",
    "-- general options:\n",
    "cmd:option('-seed', 1, 'initial random seed')\n",
    "cmd:option('-threads', 4, 'number of threads')\n",
    "\n",
    "-- gpu\n",
    "cmd:option('-cuda', false, 'cuda')\n",
    "\n",
    "-- model\n",
    "cmd:option('-lambda', 0.25, 'lambda')\n",
    "cmd:option('-action_size', 1, 'action size')\n",
    "\n",
    "-- training\n",
    "cmd:option('-batch_size', 25, 'batch size')\n",
    "cmd:option('-hist_len', 2, 'history length')\n",
    "cmd:option('-learningRate', 3e-4, 'learning rate')\n",
    "\n",
    "-- get current path\n",
    "require 'sys'\n",
    "dname, fname = sys.fpath()\n",
    "cmd:option('-save', dname, 'save path')\n",
    "cmd:option('-load', false, 'load pretrained model')\n",
    "\n",
    "cmd:option('-v', false, 'be verbose')\n",
    "cmd:text()\n",
    "\n",
    "opt = cmd:parse(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'image'\n",
    "require 'nngraph'\n",
    "require 'optim'\n",
    "require 'nn'\n",
    "require 'unsup'\n",
    "Plot = require 'itorch.Plot'\n",
    "\n",
    "require 'modules/base'\n",
    "require 'modules/KLDistCriterion'\n",
    "require 'modules/KLDCriterion'\n",
    "require 'modules/LinearO'\n",
    "require 'modules/AddCons'\n",
    "require 'modules/Reparametrize'\n",
    "\n",
    "-- Cuda initialisation\n",
    "if opt.cuda then\n",
    "    require 'cutorch'\n",
    "    require 'cunn'\n",
    "    cutorch.setDevice(1)\n",
    "    print(cutorch.getDeviceProperties(1))\n",
    "end\n",
    "\n",
    "torch.manualSeed(opt.seed)\n",
    "torch.setnumthreads(opt.threads)\n",
    "-- Set float as default type\n",
    "torch.setdefaulttensortype('torch.FloatTensor') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function disp_img(img)\n",
    "    if itorch then\n",
    "        if opt.y_mean ~= nil then\n",
    "            img = g_destandarize(img:float(), opt.y_mean, opt.y_std)\n",
    "        end\n",
    "        itorch.image(image.scale(img:float():reshape(opt.img_w, opt.img_h), 256))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local myFile = hdf5.open('data/single_pendulum_nogravity.h5', 'r')\n",
    "\n",
    "local y_all = myFile:read('train_y'):all():float()\n",
    "local u_all = myFile:read('train_u'):all():float():reshape(y_all:size(1), opt.action_size)\n",
    "\n",
    "myFile:close()\n",
    "\n",
    "-- Scale images\n",
    "-- local new_size = 10\n",
    "-- local prev_size = torch.sqrt(y_all:size(2))\n",
    "-- y_all = image.scale(y_all:reshape(y_all:size(1), prev_size,prev_size), new_size, new_size):reshape(y_all:size(1), new_size^2)\n",
    "\n",
    "-- Train Test\n",
    "local y = y_all[{{1,4900}}]\n",
    "local u = u_all[{{1,4900}}]\n",
    "\n",
    "local ys = y_all[{{4901,5000}}]\n",
    "local us = u_all[{{4901,5000}}]\n",
    "\n",
    "-- Update parameters\n",
    "opt.img_w = torch.sqrt(y:size(2))\n",
    "opt.img_h = torch.sqrt(y:size(2))\n",
    "opt.max_seq_length = y:size(1) - 1\n",
    "\n",
    "-- Store data\n",
    "state_train = {\n",
    "  x = transfer_data(y),\n",
    "  u = transfer_data(u)\n",
    "}\n",
    "\n",
    "state_test = {\n",
    "  x = transfer_data(ys),\n",
    "  u = transfer_data(us)\n",
    "}\n",
    "\n",
    "print('Train=' .. state_train.x:size(1) .. ' Test=' .. state_test.x:size(1) .. ' (' .. opt.img_w .. 'x' .. opt.img_h .. ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx=1\n",
    "disp_img(state_train.x[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function create_network()\n",
    "    \n",
    "    opt.latent_dims = 3\n",
    "    local enc_dims = 100\n",
    "    local trans_dims = 100\n",
    "    \n",
    "    -- Model Specific parameters\n",
    "    local f_maps_1 = 64\n",
    "    local f_size_1 = 7\n",
    "    local f_maps_2 = 32\n",
    "    local f_size_2 = 5\n",
    "    local f_maps_3 = 16\n",
    "    local f_size_3 = 3\n",
    "    \n",
    "    -- Encoder\n",
    "    --layer 1\n",
    "    encoder = nn.Sequential()\n",
    "    encoder:add(nn.Reshape(1, opt.hist_len, opt.img_w, opt.img_h))\n",
    "    encoder:add(nn.SpatialConvolutionMM(opt.hist_len, f_maps_1, f_size_1, f_size_1))\n",
    "    encoder:add(nn.ReLU())\n",
    "    encoder:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    \n",
    "    --layer 2\n",
    "    encoder:add(nn.SpatialConvolutionMM(f_maps_1, f_maps_2, f_size_2, f_size_2))\n",
    "    encoder:add(nn.ReLU())\n",
    "    encoder:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "    \n",
    "    encoder:add(nn.Reshape(32*6*6))\n",
    "    encoder:add(nn.LinearO(32*6*6, enc_dims))\n",
    "    encoder:add(nn.ReLU())\n",
    "        \n",
    "    encoder:add(nn.LinearO(enc_dims, enc_dims))\n",
    "    encoder:add(nn.ReLU())\n",
    "    \n",
    "    local z = nn.ConcatTable()\n",
    "    z:add(nn.LinearO(enc_dims, opt.latent_dims))\n",
    "    z:add(nn.LinearO(enc_dims, opt.latent_dims))\n",
    "    encoder:add(z)\n",
    "       \n",
    "    -- Decoder\n",
    "    local decoder = nn.Sequential()\n",
    "    decoder:add(nn.Reparametrize(opt.latent_dims))\n",
    "    decoder:add(nn.LinearO(opt.latent_dims, enc_dims))\n",
    "    decoder:add(nn.ReLU())\n",
    "\n",
    "    decoder:add(nn.LinearO(enc_dims, enc_dims))\n",
    "    decoder:add(nn.ReLU())    \n",
    "    \n",
    "    decoder:add(nn.LinearO(enc_dims, 32*9*9))\n",
    "    decoder:add(nn.ReLU())\n",
    "    \n",
    "    decoder:add(nn.Reshape(32, 9, 9))\n",
    "    \n",
    "    -- layer 2\n",
    "    decoder:add(nn.SpatialUpSamplingNearest(2))\n",
    "    decoder:add(nn.SpatialConvolutionMM(f_maps_2, f_maps_2, f_size_2, f_size_2))\n",
    "    decoder:add(nn.ReLU())\n",
    "    \n",
    "    -- layer 1\n",
    "    decoder:add(nn.SpatialUpSamplingNearest(2))\n",
    "    decoder:add(nn.SpatialConvolutionMM(f_maps_2, f_maps_1, f_size_2, f_size_2))\n",
    "    decoder:add(nn.ReLU())\n",
    "    \n",
    "    decoder:add(nn.SpatialUpSamplingNearest(2))\n",
    "    decoder:add(nn.SpatialConvolutionMM(f_maps_1, 2, f_size_2+4, f_size_2+4))\n",
    "    \n",
    "    decoder:add(nn.Sigmoid())\n",
    "    decoder:add(nn.View())\n",
    "    \n",
    "    \n",
    "    -- transition\n",
    "    local trans = nn.Sequential()\n",
    "    trans:add(nn.Reparametrize(opt.latent_dims))\n",
    "    trans:add(nn.View(opt.latent_dims))\n",
    "    trans:add(nn.LinearO(opt.latent_dims, trans_dims))\n",
    "    trans:add(nn.ReLU())\n",
    "    trans:add(nn.LinearO(trans_dims, trans_dims))\n",
    "    trans:add(nn.ReLU())\n",
    "            \n",
    "    \n",
    "    -- Define model\n",
    "    local x_t = nn.Identity()():annotate{name = 'x_t'}\n",
    "    local u_t = nn.Identity()():annotate{name = 'u_t'}\n",
    "    \n",
    "    -- Define Encoder Module\n",
    "    local z_t = encoder(x_t):annotate{name = 'z_t'}\n",
    "    \n",
    "    -- Define Transition Matrices\n",
    "    local h_trans = trans(z_t):annotate{name = 'h_trans'}\n",
    "    \n",
    "    \n",
    "    -- transition a\n",
    "    local matrix_a_vr = nn.Sequential() \n",
    "    local z = nn.ConcatTable()\n",
    "    z:add(nn.LinearO(trans_dims, opt.latent_dims))\n",
    "    z:add(nn.LinearO(trans_dims, opt.latent_dims))\n",
    "    matrix_a_vr:add(z)\n",
    "\n",
    "    local vr = matrix_a_vr(h_trans)\n",
    "    local v = nn.View(opt.latent_dims,1)(nn.SelectTable(1)(vr))\n",
    "    local r = nn.View(opt.latent_dims,1)(nn.SelectTable(2)(vr))\n",
    "    local vtr = nn.View(1,1)(nn.MM()({nn.Transpose({1,2})(v), r}))\n",
    "    local alpha = nn.Reshape(opt.latent_dims,opt.latent_dims)(\n",
    "        nn.Replicate(opt.latent_dims*opt.latent_dims)(\n",
    "            nn.AddConstant(1)(nn.MulConstant(-1)(vtr))\n",
    "        ))\n",
    "    local vrt = nn.View(opt.latent_dims,opt.latent_dims)(nn.MM()({v, nn.Transpose({1,2})(r)}))\n",
    "    local matrix_a = nn.View(opt.latent_dims,opt.latent_dims)(\n",
    "        nn.AddCons(torch.eye(opt.latent_dims,opt.latent_dims))(\n",
    "            nn.CDivTable()({vrt, alpha})\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    -- local matrix_a = nn.Sequential()\n",
    "    -- matrix_a:add(nn.LinearO(trans_dims, opt.latent_dims*opt.latent_dims))\n",
    "    -- matrix_a:add(nn.View(opt.latent_dims, opt.latent_dims))\n",
    "        \n",
    "    -- transition b\n",
    "    local matrix_b = nn.Sequential()\n",
    "    matrix_b:add(nn.LinearO(trans_dims, opt.latent_dims*opt.action_size))\n",
    "    matrix_b:add(nn.View(opt.latent_dims, opt.action_size))\n",
    "    \n",
    "    -- transition o\n",
    "    local matrix_o = nn.Sequential()\n",
    "    matrix_o:add(nn.LinearO(trans_dims, opt.latent_dims))\n",
    "    matrix_o:add(nn.View(opt.latent_dims, 1))\n",
    "    \n",
    "\n",
    "    local a_t = matrix_a:annotate{name = 'a_t'}\n",
    "    -- local a_t = matrix_a(h_trans):annotate{name = 'a_t'}\n",
    "    local a_t2 = nn.Power(2)(a_t):annotate{name = 'a_t2'}\n",
    "    local b_t = matrix_b(h_trans):annotate{name = 'b_t'}\n",
    "    local o_t = matrix_o(h_trans):annotate{name = 'o_t'}\n",
    "    \n",
    "    local a_t_z_t = nn.MM()({\n",
    "            a_t, nn.View(opt.latent_dims, 1)(nn.SelectTable(1)(z_t))\n",
    "        }):annotate{name = 'a_t_z_t'}\n",
    "    \n",
    "    local b_t_u_t = nn.MM()({\n",
    "            b_t, nn.View(opt.action_size, 1)(u_t)\n",
    "        }):annotate{name = 'b_t_u_t'}\n",
    "    \n",
    "    -- Define Dynamics Model\n",
    "    local dynamics_mean = nn.Transpose({1,2})(\n",
    "        nn.CAddTable()({a_t_z_t, b_t_u_t, o_t})\n",
    "    ):annotate{name = 'dynamics_mean'}\n",
    "    \n",
    "    local dynamics_var = nn.Transpose({1,2})(nn.Log()(\n",
    "        nn.MM()({\n",
    "            a_t2, nn.View(opt.latent_dims, 1)(nn.Exp()(nn.SelectTable(2)(z_t)))\n",
    "    }))):annotate{name = 'dynamics_var'}\n",
    "    \n",
    "    local dynamics_all = nn.Identity()({dynamics_mean, dynamics_var}):annotate{name = 'dynamics'}\n",
    "    \n",
    "    -- Define Output\n",
    "    local output_t1 = decoder(dynamics_all):annotate{name = 'decoder_x_t1'}\n",
    "    local decoder2 = decoder:clone(\"weight\", \"bias\", \"gradWeight\", \"gradBias\")\n",
    "    local output_t = decoder2(z_t):annotate{name = 'decoder_x_t'}\n",
    "    \n",
    "    -- Create model\n",
    "    model = nn.gModule({x_t, u_t}, {z_t, output_t, dynamics_all, output_t1})\n",
    "    \n",
    "    -- Create Links to modules\n",
    "    create_links(model)\n",
    "    \n",
    "    return model\n",
    "end\n",
    "\n",
    "function create_links(model)\n",
    "\n",
    "    -- Create links to decoder and dynamics model\n",
    "    node_encoder = 5\n",
    "    node_dynamics = 44\n",
    "    node_decoder = 6\n",
    "    node_decoder2 = 45\n",
    "    \n",
    "    -- Clone Dynamics model only and share parameters\n",
    "    dynamics = model:clone(\"weight\", \"bias\", \"gradWeight\", \"gradBias\")\n",
    "    dynamics.forwardnodes[node_encoder].data.module = nil\n",
    "    dynamics.forwardnodes[node_decoder].data.module = nil\n",
    "    dynamics.forwardnodes[node_decoder2].data.module = nil\n",
    "    for indexNode,node in ipairs(dynamics.forwardnodes) do\n",
    "         if dynamics.forwardnodes[indexNode].data.module then\n",
    "            dynamics.forwardnodes[indexNode].data.module = model.forwardnodes[indexNode].data.module\n",
    "        end\n",
    "    end\n",
    "    dynamics.forwardnodes[node_encoder].data.module = nn.Identity()\n",
    "    dynamics.forwardnodes[node_decoder].data.module = nn.Identity()\n",
    "    dynamics.forwardnodes[node_decoder2].data.module = nn.Identity()\n",
    "\n",
    "    encoder = model.forwardnodes[node_encoder].data.module\n",
    "    decoder = model.forwardnodes[node_decoder].data.module\n",
    "    \n",
    "    ae = nn.Sequential()\n",
    "    ae:add(encoder)\n",
    "    ae:add(decoder)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Network function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function setup()\n",
    "    print(\"Creating Conv-Net.\")\n",
    "    model = create_network()\n",
    "    params, gradParams = model:getParameters()\n",
    "    \n",
    "    criterion = nn.BCECriterion()\n",
    "    criterion.sizeAverage = false\n",
    "\n",
    "    KLD = nn.KLDCriterion()\n",
    "    KLD.sizeAverage = false\n",
    "    \n",
    "    KLDist = nn.KLDistCriterion()\n",
    "    KLDist.sizeAverage = false\n",
    "end\n",
    "\n",
    "function setup_load()\n",
    "    \n",
    "    print(\"Loading Conv-Net.\")\n",
    "    \n",
    "    load_model()\n",
    "    \n",
    "    create_links(model)\n",
    "    \n",
    "    params, gradParams = model:getParameters()\n",
    "    \n",
    "    opt.load = true\n",
    "    \n",
    "    dname, fname = sys.fpath()\n",
    "    opt.save = dname\n",
    "    \n",
    "    criterion = nn.BCECriterion()\n",
    "    criterion.sizeAverage = false\n",
    "\n",
    "    KLD = transfer_data(nn.KLDCriterion())\n",
    "    KLD.sizeAverage = false\n",
    "    \n",
    "    KLDist = nn.KLDistCriterion()\n",
    "    KLDist.sizeAverage = false\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function save_model()\n",
    "    -- save/log current net\n",
    "    local filename = paths.concat(opt.save, 'model/relu_single_nogravity_e2c_conv.t7')\n",
    "    os.execute('mkdir -p ' .. paths.dirname(filename))\n",
    "    if paths.filep(filename) then\n",
    "        os.execute('mv ' .. filename .. ' ' .. filename .. '.old')\n",
    "    end\n",
    "    -- print('<trainer> saving network to '..filename)\n",
    "    torch.save(filename, {model, opt, optim_config, train_err, test_err})\n",
    "end\n",
    "\n",
    "function load_model()\n",
    "    model, opt, optim_config, train_err, test_err = unpack(torch.load('model/relu_single_nogravity_e2c_conv.t7'))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Network parameters:\")\n",
    "print(opt)\n",
    "\n",
    "if opt.load then\n",
    "    setup_load()\n",
    "else\n",
    "    setup()\n",
    "    optim_config = { learningRate = -opt.learningRate,\n",
    "                     beta2 = 0.9\n",
    "                    }\n",
    "    train_err = {}\n",
    "    test_err = {}\n",
    "end\n",
    "\n",
    "epoch = #train_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function run_test(dataset) \n",
    "\n",
    "    local err_cur = 0\n",
    "    local err_next = 0\n",
    "    \n",
    "    local loss = nn.BCECriterion()\n",
    "\n",
    "    for idx = 2, dataset.x:size(1)-1 do\n",
    "\n",
    "        local x_prev = dataset.x[idx-1]\n",
    "        local x_cur = dataset.x[idx]\n",
    "        local x_next = dataset.x[idx+1]\n",
    "        local batch_u = dataset.u[idx]\n",
    "        \n",
    "        local batch_x = torch.cat(x_prev,x_cur)\n",
    "        local batch_y = torch.cat(x_cur,x_next)\n",
    "\n",
    "        -- Forward\n",
    "        local z_t, x_t, z_t1, x_t1 = unpack(model:forward({batch_x, batch_u}))\n",
    "        err_cur = err_cur + loss:forward(x_t, batch_x)\n",
    "        err_next = err_next + loss:forward(x_t1:split(opt.img_w^2)[2], x_next)\n",
    "        -- err_next = err_next + loss:forward(x_t1, batch_y)\n",
    "\n",
    "    end\n",
    "    \n",
    "    return err_cur / (dataset.x:size(1) - 2), err_next / (dataset.x:size(1) - 2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_create_batch(state_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function train(dataset)\n",
    "\n",
    "    -- epoch tracker\n",
    "    epoch = epoch or 0\n",
    "    \n",
    "    -- load minibatch\n",
    "    g_create_batch(state_train)\n",
    "\n",
    "    -- local vars\n",
    "    local err = {all=0, bce=0, bce_1=0, kl=0, kld=0}\n",
    "\n",
    "    -- shuffle at each epoch\n",
    "    local shuffle = torch.randperm(#dataset.batch):long()\n",
    "\n",
    "    for t = 1,#dataset.batch do\n",
    "\n",
    "        -- create mini batch\n",
    "        local batch_x = dataset.batch[shuffle[t]][1]\n",
    "        local batch_u = dataset.batch[shuffle[t]][2]\n",
    "        local batch_y = dataset.batch[shuffle[t]][3]\n",
    "\n",
    "        -- create closure to evaluate f(X) and df/dX\n",
    "        local feval = function(x)\n",
    "            \n",
    "            -- get new parameters\n",
    "            if x ~= params then\n",
    "                params:copy(x)\n",
    "            end\n",
    "\n",
    "            -- reset gradients\n",
    "            gradParams:zero()\n",
    "            \n",
    "            -- reset errors\n",
    "            local bce_err, bce_1_err, kl_err, kld_err = 0, 0, 0, 0\n",
    "            \n",
    "            -- evaluate function for complete mini batch\n",
    "            for i = 1,#batch_x do\n",
    "                \n",
    "                local enc_y = encoder:forward(batch_y[i])\n",
    "                                \n",
    "                local z_t, x_t, z_t1, x_t1 = unpack(model:forward({batch_x[i], batch_u[i]}))  \n",
    "                                \n",
    "                -- BCE x_t\n",
    "                bce_err = bce_err - criterion:forward(x_t, batch_x[i])\n",
    "                local d_x_t = criterion:backward(x_t, batch_x[i]):clone():mul(-1)\n",
    "                \n",
    "                -- KL Divergence z_t\n",
    "                kl_err = kl_err + KLD:forward(z_t, batch_x[i])\n",
    "                local d_z_t = KLD:backward(z_t, batch_x[i])\n",
    "                \n",
    "                -- BCE x_t+1\n",
    "                bce_1_err = bce_1_err - criterion:forward(x_t1, batch_y[i])\n",
    "                local d_x_t1 = criterion:backward(x_t1, batch_y[i]):clone():mul(-1)\n",
    "                                \n",
    "                -- KL Divergence z^_t+1 ~ z_t+1 \n",
    "                kld_err = kld_err + KLDist:forward(z_t1, enc_y) * opt.lambda\n",
    "                local d_z_t1 = KLDist:backward(z_t1, enc_y)\n",
    "                d_z_t1[1]:mul(opt.lambda)\n",
    "                d_z_t1[2]:mul(opt.lambda)\n",
    "                             \n",
    "                -- Backpropagate\n",
    "                model:backward({batch_x[i], batch_u[i]}, {\n",
    "                        d_z_t,\n",
    "                        d_x_t,\n",
    "                        d_z_t1,\n",
    "                        d_x_t1\n",
    "                    })     \n",
    "                \n",
    "            end\n",
    "            \n",
    "            -- Accumulate errors\n",
    "            err.bce = err.bce + bce_err\n",
    "            err.bce_1 = err.bce_1 + bce_1_err\n",
    "            err.kl = err.kl + kl_err\n",
    "            err.kld = err.kld + kld_err\n",
    "            err.all = err.all + bce_err + bce_1_err + kl_err + kld_err\n",
    "                        \n",
    "            -- normalize gradients and f(X)\n",
    "            local batcherr = (bce_err + bce_1_err + kl_err + kld_err) / #batch_x           \n",
    "            gradParams:div(#batch_x)\n",
    "                \n",
    "            print(bce_err/#batch_x, bce_1_err/#batch_x, kl_err/#batch_x, kld_err/#batch_x)\n",
    "                \n",
    "            -- return f and df/dX\n",
    "            return batcherr, gradParams\n",
    "        end\n",
    "        \n",
    "        if #batch_x > 0 then\n",
    "            optim.adam(feval, params, optim_config)\n",
    "            -- optim.adagrad(feval, params, optim_config)\n",
    "            -- optim.rmsprop(feval, params, optim_config)\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    -- Normalise errors\n",
    "    err.all = err.all / (dataset.x:size(1) - 2)\n",
    "    err.bce = err.bce / (dataset.x:size(1) - 2)\n",
    "    err.bce_1 = err.bce_1 / (dataset.x:size(1) - 2)\n",
    "    err.kl = err.kl / (dataset.x:size(1) - 2)\n",
    "    err.kld = err.kld / (dataset.x:size(1) - 2)\n",
    "    \n",
    "    collectgarbage()\n",
    "\n",
    "    epoch = epoch + 1\n",
    "\n",
    "    return err\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "-- epochs to run\n",
    "opt.max_epoch = 3\n",
    "\n",
    "-- start time\n",
    "local beginning_time = torch.tic()\n",
    "\n",
    "-- iterate through epochs\n",
    "for e = 1, opt.max_epoch do\n",
    "    \n",
    "    -- local vars\n",
    "    local time = sys.clock()\n",
    "    \n",
    "    -- train for 1 epoch\n",
    "    local err = train(state_train)\n",
    "        \n",
    "    train_err[#train_err+1] = err\n",
    "    \n",
    "    -- time taken\n",
    "    time = sys.clock() - time\n",
    "    \n",
    "    -- display stats\n",
    "    if (epoch) % 1 == 0 then\n",
    "        \n",
    "        local since_beginning = g_d(torch.toc(beginning_time) / 60)\n",
    "        print('epoch=' .. (epoch) ..\n",
    "          ', Train err=' .. g_f3(train_err[#train_err].all) ..\n",
    "          ', bce=' .. g_f3(train_err[#train_err].bce) ..\n",
    "          ', bce_1=' .. g_f3(train_err[#train_err].bce_1) ..\n",
    "          ', kl=' .. g_f3(train_err[#train_err].kl) ..\n",
    "          ', kld=' .. g_f3(train_err[#train_err].kld) ..\n",
    "          -- ', Test err=' .. g_f5(test_err[#test_err]) ..\n",
    "          ', t/epoch = ' .. g_f3(time) .. ' sec' ..\n",
    "          ', since beginning = ' .. since_beginning .. ' mins.')\n",
    "\n",
    "        if (epoch) % 1 == 0 then\n",
    "            save_model()\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_error(err, criterion)\n",
    "    local criterion = criterion or 'all'\n",
    "    local arr = torch.zeros(#err)\n",
    "    for i=1,#err do arr[i] = -err[i][criterion] end    \n",
    "    return arr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = {'blue', 'green', 'red', 'purple', 'orange', 'magenta', 'cyan'}\n",
    "plot = Plot()\n",
    "plot:title(string.format('Neural Net Performance in %d epochs', #train_err))\n",
    "plot = plot:line(torch.range(1,#train_err), get_error(train_err,'all'), colors[1], 'All')\n",
    "plot = plot:line(torch.range(1,#train_err), get_error(train_err,'bce'), colors[2], 'BCE')\n",
    "plot = plot:line(torch.range(1,#train_err), get_error(train_err,'bce_1'), colors[3], 'BCE_1')\n",
    "plot = plot:line(torch.range(1,#train_err), get_error(train_err,'kl'), colors[4], 'KL')\n",
    "plot = plot:line(torch.range(1,#train_err), get_error(train_err,'kld'), colors[5], 'KLD')\n",
    "plot:legend(true):redraw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
